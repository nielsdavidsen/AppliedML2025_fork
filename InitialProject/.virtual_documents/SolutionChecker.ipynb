





directory = 'solutions'





import os

def init_entry():
    tmp = {}
    tmp['Classification'] = {}
    tmp['Regression'] = {}
    tmp['Clustering'] = {}
    return tmp

def read_filenames(directory):
    tmp = {}
    for filename in os.listdir(directory):
        full_path = f'{directory}/{filename}'
        if not os.path.isfile(full_path) or not filename.endswith('.csv'):
            continue
        splitted = filename.split('_')
        
        project_part = splitted[0]
        student_name = splitted[1]
        is_varlist = splitted[-1].lower() == 'variablelist.csv'
        implementation = splitted[-2] if is_varlist else splitted[-1].split('.csv')[0]
        
        if student_name not in tmp:
            tmp[student_name] = init_entry()
        if implementation not in tmp[student_name][project_part]:
            tmp[student_name][project_part][implementation] = {}
        
        if is_varlist:
            tmp[student_name][project_part][implementation]['vars'] = full_path
        else:
            tmp[student_name][project_part][implementation]['preds'] = full_path
    return tmp

all_errors = 0
errors = 0
def write_error(msg, cap=5):
    global errors
    if errors < cap:
        print (msg)
    errors += 1

names = read_filenames(directory)





all_errors += errors
errors = 0

for name, parts in names.items():
    print (f'{name}:')
    for part, implementations in parts.items():
        print (f'    {part}:')
        if len(implementations) == 0:
            write_error(f'        {part} does not have any files')
        else:
            for implementation, files in implementations.items():
                if ('vars' not in files) and ('preds' not in files):
                    write_error(f'            {implementation} does not have a full prediction/variablelist set')
                else:
                    print (f'        {implementation}:')
                    print (f'            preds: {files["preds"]}')
                    print (f'            vars:  {files["vars"]}')

if errors == 0:
    print ('Files read succesfully')
else:
    print (f'Reading files gave {errors} errors')





all_variables = [
    "averageInteractionsPerCrossing","p_Rhad1","p_Rhad","p_f3","p_weta2","p_Rphi","p_Reta","p_Eratio","p_f1","p_TRTPID","p_numberOfInnermostPixelHits","p_numberOfPixelHits","p_numberOfSCTHits","p_numberOfTRTHits","p_TRTTrackOccupancy","p_numberOfTRTXenonHits","p_z0","p_d0","p_sigmad0","p_dPOverP","p_deltaEta1","p_deltaPhiRescaled2","p_etcone20","p_etcone30","p_etcone40","p_ptcone20","p_ptcone30","p_ptcone40","p_ptPU30","p_vertex","pX_E7x7_Lr2","pX_E7x7_Lr3","pX_E_Lr0_HiG","pX_E_Lr0_MedG","pX_E_Lr1_HiG","pX_E_Lr1_LowG","pX_E_Lr1_MedG","pX_E_Lr2_HiG","pX_E_Lr2_LowG","pX_E_Lr2_MedG","pX_E_Lr3_HiG","pX_E_Lr3_MedG","pX_MultiLepton","pX_OQ","pX_ambiguityType","pX_asy1","pX_author","pX_barys1","pX_core57cellsEnergyCorrection","pX_deltaEta0","pX_deltaEta1","pX_deltaEta2","pX_deltaEta3","pX_deltaPhi0","pX_deltaPhi1","pX_deltaPhi2","pX_deltaPhi3","pX_deltaPhiFromLastMeasurement","pX_deltaPhiRescaled0","pX_deltaPhiRescaled1","pX_deltaPhiRescaled3","pX_e1152","pX_e132","pX_e235","pX_e255","pX_e2ts1","pX_ecore","pX_emins1","pX_etcone20","pX_etcone30","pX_etcone40","pX_f1core","pX_f3core","pX_maxEcell_energy","pX_maxEcell_gain","pX_maxEcell_time","pX_maxEcell_x","pX_maxEcell_y","pX_maxEcell_z","pX_nCells_Lr0_HiG","pX_nCells_Lr0_MedG","pX_nCells_Lr1_HiG","pX_nCells_Lr1_LowG","pX_nCells_Lr1_MedG","pX_nCells_Lr2_HiG","pX_nCells_Lr2_LowG","pX_nCells_Lr2_MedG","pX_nCells_Lr3_HiG","pX_nCells_Lr3_MedG","pX_neflowisol20","pX_neflowisol30","pX_neflowisol40","pX_neflowisolcoreConeEnergyCorrection","pX_pos","pX_pos7","pX_poscs1","pX_poscs2","pX_ptcone20","pX_ptcone30","pX_ptcone40","pX_ptconecoreTrackPtrCorrection","pX_ptvarcone20","pX_ptvarcone30","pX_ptvarcone40","pX_r33over37allcalo","pX_topoetcone20","pX_topoetcone20ptCorrection","pX_topoetcone30","pX_topoetcone30ptCorrection","pX_topoetcone40","pX_topoetcone40ptCorrection","pX_topoetconecoreConeEnergyCorrection","pX_weta1","pX_widths1","pX_wtots1","pX_e233","pX_e237","pX_e2tsts1","pX_ehad1","pX_emaxs1","pX_fracs1","pX_DeltaE","pX_E3x5_Lr0","pX_E3x5_Lr1","pX_E3x5_Lr2","pX_E3x5_Lr3","pX_E5x7_Lr0","pX_E5x7_Lr1","pX_E5x7_Lr2","pX_E5x7_Lr3","pX_E7x11_Lr0","pX_E7x11_Lr1","pX_E7x11_Lr2","pX_E7x11_Lr3","pX_E7x7_Lr0","pX_E7x7_Lr1","p_pt_track","p_eta","p_phi","p_charge"
]
max_variables = {
    'Classification': 20,
    'Regression': 25,
    'Clustering':  10,
}

all_errors += errors
errors = 0
for student_name, parts in names.items():
    for part, implementations in parts.items():
        for implementation, files in implementations.items():
            file = files['vars']
            count = 0
            with open(file, 'r') as f:
                for line in f:
                    var_name = line.rstrip()
                    if var_name.endswith(","):
                        var_name = var_name[:-1]
                    if var_name not in all_variables:
                        write_error(f'Variable {var_name} not in the given variable list {file}')
                    else:
                        count += 1
            if count > max_variables[part]:
                write_error(f'Used too many variables ({count}/{max_variables[part]}) for {part}: {file}')
                    
if errors == 0:
    print ('Variables parsed without error')
else:
    print (f'Variables had {errors} errors')





test_entries_class = 60000
test_entries_regre = 40000
test_entries_clust = 20000

prediction_range = {
    'Classification': (0.0, 1.0),
    'Regression': (-float('inf'), float('inf')),
    'Clustering': (-float('inf'), float('inf')),
}

all_errors += errors
errors = 0
for student_name, parts in names.items():
    for part, implementations in parts.items():
        for implementation, files in implementations.items():
            file = files['preds']
            with open(file, 'r') as f:
                lines = [line for line in f]
            for i in range(len(lines)):
                if ',' in lines[i]:
                    index, value = lines[i].lstrip().rstrip().split(',')
                    try:
                        if int(index) != i:
                            write_error(f'Index at line {i+1} does not have correct index: {index}')
                    except ValueError:
                        write_error(f'Unable to cast the index to an integer: {index} in {file}')
                else:
                    value = lines[i].lstrip().rstrip()
                value = float(value)
                if part == 'Clustering':
                    if value.is_integer():
                        value = int(value)
                    else:
                        write_error(f'Clustering value at {i} is not an integer: {value} in {file}')
                        continue
                mi, ma = prediction_range[part]
                if not (value >= mi and value <= ma):
                    write_error(f'Value at {i} is not in the permitted range of ({mi},{ma}): {value} in {file}')
            if part == 'Classification':
                if len(lines) != test_entries_class:
                    write_error(f'Not correct number of predictions for classification. Got {len(lines)}, expected {test_entries_class}')
            if part == 'Regression':
                if len(lines) != test_entries_regre:
                    write_error(f'Not correct number of predictions for regression. Got {len(lines)}, expected {test_entries_regre}')
            if part == 'Clustering':
                if len(lines) != test_entries_clust:
                    write_error(f'Not correct number of predictions for clustering. Got {len(lines)}, expected {test_entries_clust}')
                
if errors == 0:
    print ('Solutions parsed without error')
else:
    print (f'Solutions had {errors} errors')





if all_errors == 0:
    print ('All parts of this submission had no errors')
else:
    print (f'This submission had {all_errors} errors')





!jupyter nbconvert --to script SolutionReader.ipynb
