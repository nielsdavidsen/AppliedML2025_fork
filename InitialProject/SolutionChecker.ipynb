{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppliedML Initial Project solution file reader\n",
    "\n",
    "This notebook is used for reading solutions to the initial project and checking that they are valid.\n",
    "\n",
    "Note: It will only print the first 5 error messages of each check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining the folder holding the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'solutions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we read all the files in the folder, which correspond to the format, and verify the prediction/variablelist pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def init_entry():\n",
    "    tmp = {}\n",
    "    tmp['Classification'] = {}\n",
    "    tmp['Regression'] = {}\n",
    "    tmp['Clustering'] = {}\n",
    "    return tmp\n",
    "\n",
    "def read_filenames(directory):\n",
    "    tmp = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        if not os.path.isfile(full_path) or not filename.lower().endswith('.csv'):\n",
    "            print(f\"Skipping {filename} as it is not a CSV file.\")\n",
    "            continue\n",
    "        splitted = filename.split('_')\n",
    "        if len(splitted) != 3 and len(splitted) != 4:\n",
    "            write_error(f\"Filename '{filename}' does not match expected format \\n 'TypeOfProblemSolved_FirstnameLastname_SolutionName(_VariableList).csv! \\n Your solution includes {len(splitted)} parts instead of 3 or 4. \\n Please check the filename and try again.\")\n",
    "            continue\n",
    "\n",
    "        if len(splitted) == 4 and not splitted[-1].lower() == 'variablelist.csv':\n",
    "            write_error(f\" Your filename '{filename}' includes 4 parts, but the last part is not VariableList.csv. \\n Please check the filename and try again.\")\n",
    "\n",
    "        project_part = splitted[0]\n",
    "        student_name = splitted[1]\n",
    "        is_varlist = splitted[-1].lower() == 'variablelist.csv'\n",
    "        implementation = splitted[-2] if is_varlist else splitted[-1].split('.csv')[0]\n",
    "\n",
    "        if project_part not in ['Classification', 'Regression', 'Clustering']:\n",
    "            write_error(f\"Filename '{filename}' does not match expected format \\n 'TypeOfProblemSolved_FirstnameLastname_SolutionName(_VariableList).csv! \\n Your solution includes {project_part} instead of Classification, Regression or Clustering. \\n Please check the filename and try again.\")\n",
    "            continue\n",
    "        \n",
    "        if student_name not in tmp:\n",
    "            tmp[student_name] = init_entry()\n",
    "        \n",
    "        if implementation not in tmp[student_name][project_part]:\n",
    "            tmp[student_name][project_part][implementation] = {}\n",
    "        \n",
    "        if is_varlist:\n",
    "            tmp[student_name][project_part][implementation]['vars'] = full_path\n",
    "\n",
    "        else:\n",
    "            tmp[student_name][project_part][implementation]['preds'] = full_path\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "all_errors = 0\n",
    "errors = 0\n",
    "def write_error(msg, cap=5):\n",
    "    global errors\n",
    "    if errors < cap:\n",
    "        print (msg)\n",
    "    errors += 1\n",
    "    if errors >= cap:\n",
    "        print(\"Too many errors, stopping further checks.\")\n",
    "        exit(1)\n",
    "\n",
    "names = read_filenames(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can print the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JohannNikolaides:\n",
      "    Classification:\n",
      "        LightGBM:\n",
      "dict_keys(['vars', 'preds'])\n",
      "            preds: solutions/Classification_JohannNikolaides_LightGBM.csv\n",
      "             vars:  solutions/Classification_JohannNikolaides_LightGBM_VariableList.csv\n",
      "    Regression:\n",
      "        LightGBM:\n",
      "dict_keys(['vars', 'preds'])\n",
      "            preds: solutions/Regression_JohannNikolaides_LightGBM.csv\n",
      "             vars:  solutions/Regression_JohannNikolaides_LightGBM_VariableList.csv\n",
      "    Clustering:\n",
      "        HDBSCAN:\n",
      "dict_keys(['vars', 'preds'])\n",
      "            preds: solutions/Clustering_JohannNikolaides_HDBSCAN.csv\n",
      "             vars:  solutions/Clustering_JohannNikolaides_HDBSCAN_VariableList.csv\n",
      "Files read succesfully\n"
     ]
    }
   ],
   "source": [
    "all_errors += errors\n",
    "errors = 0\n",
    "\n",
    "for name, parts in names.items():\n",
    "    print (f'{name}:')\n",
    "    for part, implementations in parts.items():\n",
    "        print (f'    {part}:')\n",
    "        if len(implementations) == 0:\n",
    "            write_error(f'        {part} does not have any files')\n",
    "        else:\n",
    "            for implementation, files in implementations.items():\n",
    "                if ('vars' not in files) and ('preds' not in files):\n",
    "                    write_error(f\"            {implementation} should have at least a 'VariableList' file and a prediction file\")\n",
    "                else:\n",
    "                    print (f'        {implementation}:')\n",
    "                    print(files.keys())\n",
    "                    print (f'            preds: {files[\"preds\"]}')\n",
    "                    print (f'             vars:  {files[\"vars\"]}')\n",
    "\n",
    "if errors == 0:\n",
    "    print ('Files read succesfully')\n",
    "else:\n",
    "    print (f'Reading files gave {errors} errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we verify the VariableList files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skipping empty line in Clustering file: solutions/Clustering_JohannNikolaides_HDBSCAN_VariableList.csv\n",
      "Variables parsed without error\n"
     ]
    }
   ],
   "source": [
    "clustering_vars = [\n",
    "    'Unnamed: 0', 'J', 'H', 'K', 'C_FE', 'N_FE', 'O_FE', 'NA_FE', 'MG_FE', 'AL_FE', 'SI_FE', 'CA_FE', 'S_FE', 'V_FE', 'CR_FE', 'FE_H', 'CO_FE', 'NI_FE', 'E', 'Energy', 'Lz'\n",
    "    ]\n",
    "\n",
    "class_reg_vars = [\n",
    "    \"averageInteractionsPerCrossing\",\"p_Rhad1\",\"p_Rhad\",\"p_f3\",\"p_weta2\",\"p_Rphi\",\"p_Reta\",\"p_Eratio\",\"p_f1\",\"p_TRTPID\",\"p_numberOfInnermostPixelHits\",\"p_numberOfPixelHits\",\"p_numberOfSCTHits\",\"p_numberOfTRTHits\",\"p_TRTTrackOccupancy\",\"p_numberOfTRTXenonHits\",\"p_z0\",\"p_d0\",\"p_sigmad0\",\"p_dPOverP\",\"p_deltaEta1\",\"p_deltaPhiRescaled2\",\"p_etcone20\",\"p_etcone30\",\"p_etcone40\",\"p_ptcone20\",\"p_ptcone30\",\"p_ptcone40\",\"p_ptPU30\",\"p_vertex\",\"pX_E7x7_Lr2\",\"pX_E7x7_Lr3\",\"pX_E_Lr0_HiG\",\"pX_E_Lr0_MedG\",\"pX_E_Lr1_HiG\",\"pX_E_Lr1_LowG\",\"pX_E_Lr1_MedG\",\"pX_E_Lr2_HiG\",\"pX_E_Lr2_LowG\",\"pX_E_Lr2_MedG\",\"pX_E_Lr3_HiG\",\"pX_E_Lr3_MedG\",\"pX_MultiLepton\",\"pX_OQ\",\"pX_ambiguityType\",\"pX_asy1\",\"pX_author\",\"pX_barys1\",\"pX_core57cellsEnergyCorrection\",\"pX_deltaEta0\",\"pX_deltaEta1\",\"pX_deltaEta2\",\"pX_deltaEta3\",\"pX_deltaPhi0\",\"pX_deltaPhi1\",\"pX_deltaPhi2\",\"pX_deltaPhi3\",\"pX_deltaPhiFromLastMeasurement\",\"pX_deltaPhiRescaled0\",\"pX_deltaPhiRescaled1\",\"pX_deltaPhiRescaled3\",\"pX_e1152\",\"pX_e132\",\"pX_e235\",\"pX_e255\",\"pX_e2ts1\",\"pX_ecore\",\"pX_emins1\",\"pX_etcone20\",\"pX_etcone30\",\"pX_etcone40\",\"pX_f1core\",\"pX_f3core\",\"pX_maxEcell_energy\",\"pX_maxEcell_gain\",\"pX_maxEcell_time\",\"pX_maxEcell_x\",\"pX_maxEcell_y\",\"pX_maxEcell_z\",\"pX_nCells_Lr0_HiG\",\"pX_nCells_Lr0_MedG\",\"pX_nCells_Lr1_HiG\",\"pX_nCells_Lr1_LowG\",\"pX_nCells_Lr1_MedG\",\"pX_nCells_Lr2_HiG\",\"pX_nCells_Lr2_LowG\",\"pX_nCells_Lr2_MedG\",\"pX_nCells_Lr3_HiG\",\"pX_nCells_Lr3_MedG\",\"pX_neflowisol20\",\"pX_neflowisol30\",\"pX_neflowisol40\",\"pX_neflowisolcoreConeEnergyCorrection\",\"pX_pos\",\"pX_pos7\",\"pX_poscs1\",\"pX_poscs2\",\"pX_ptcone20\",\"pX_ptcone30\",\"pX_ptcone40\",\"pX_ptconecoreTrackPtrCorrection\",\"pX_ptvarcone20\",\"pX_ptvarcone30\",\"pX_ptvarcone40\",\"pX_r33over37allcalo\",\"pX_topoetcone20\",\"pX_topoetcone20ptCorrection\",\"pX_topoetcone30\",\"pX_topoetcone30ptCorrection\",\"pX_topoetcone40\",\"pX_topoetcone40ptCorrection\",\"pX_topoetconecoreConeEnergyCorrection\",\"pX_weta1\",\"pX_widths1\",\"pX_wtots1\",\"pX_e233\",\"pX_e237\",\"pX_e2tsts1\",\"pX_ehad1\",\"pX_emaxs1\",\"pX_fracs1\",\"pX_DeltaE\",\"pX_E3x5_Lr0\",\"pX_E3x5_Lr1\",\"pX_E3x5_Lr2\",\"pX_E3x5_Lr3\",\"pX_E5x7_Lr0\",\"pX_E5x7_Lr1\",\"pX_E5x7_Lr2\",\"pX_E5x7_Lr3\",\"pX_E7x11_Lr0\",\"pX_E7x11_Lr1\",\"pX_E7x11_Lr2\",\"pX_E7x11_Lr3\",\"pX_E7x7_Lr0\",\"pX_E7x7_Lr1\",\"p_pt_track\",\"p_eta\",\"p_phi\",\"p_charge\"\n",
    "]\n",
    "\n",
    "all_variables = class_reg_vars + clustering_vars\n",
    "\n",
    "max_variables = {\n",
    "    'Classification': 25,\n",
    "    'Regression': 12,\n",
    "    'Clustering':  7,\n",
    "}\n",
    "\n",
    "all_errors += errors\n",
    "errors = 0\n",
    "for student_name, parts in names.items():\n",
    "    for part, implementations in parts.items():\n",
    "        for implementation, files in implementations.items():\n",
    "            file = files['vars']\n",
    "            count = 0\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    var_name = line.rstrip()\n",
    "                    if var_name == \"\":\n",
    "                        print(f\" Skipping empty line in {part} file: {file}\")\n",
    "                        continue\n",
    "                    if var_name.endswith(\",\"):\n",
    "                        var_name = var_name[:-1]\n",
    "                    if var_name not in all_variables:\n",
    "                        write_error(f\"Variable '{var_name}' not in the given variable list. Check file: {file}\")\n",
    "                    else:\n",
    "                        count += 1\n",
    "            if count > max_variables[part]:\n",
    "                write_error(f'Used too many variables ({count}/{max_variables[part]}) for {part}: {file}')\n",
    "                    \n",
    "if errors == 0:\n",
    "    print ('Variables parsed without error')\n",
    "else:\n",
    "    print (f'Variables had {errors} errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can verify than the solution files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions parsed without error\n"
     ]
    }
   ],
   "source": [
    "test_entries_class = 60000\n",
    "test_entries_regre = 40000\n",
    "test_entries_clust = 5950\n",
    "\n",
    "prediction_range = {\n",
    "    'Classification': (0.0, 1.0),\n",
    "    'Regression': (-float('inf'), float('inf')),\n",
    "    'Clustering': (-float('inf'), float('inf')),\n",
    "}\n",
    "\n",
    "all_errors += errors\n",
    "errors = 0\n",
    "for student_name, parts in names.items():\n",
    "    for part, implementations in parts.items():\n",
    "        for implementation, files in implementations.items():\n",
    "            file = files['preds']\n",
    "            with open(file, 'r') as f:\n",
    "                lines = [line for line in f]\n",
    "            for i in range(len(lines)):\n",
    "                if ',' in lines[i]:\n",
    "                    try:\n",
    "                        index, value = lines[i].lstrip().rstrip().split(',')\n",
    "                    except ValueError:\n",
    "                        write_error(f\"Expected an index and a value but got more at line {i+1}: {lines[i]} in {part} file: {file}\")\n",
    "                        continue\n",
    "                    try:\n",
    "                        if int(index) != i:\n",
    "                            write_error(f'Index at line {i+1} does not have correct index: {index}. Check {part} file: {file}')\n",
    "                    except ValueError:\n",
    "                        write_error(f'Unable to cast the index to an integer: {index} in {file}')\n",
    "                else:\n",
    "                    value = lines[i].lstrip().rstrip()\n",
    "                    \n",
    "                try:\n",
    "                    value = float(value)\n",
    "                except ValueError:\n",
    "                    write_error(f\"Value at line {i+1} is not a valid floating point number: {value} in {part} file: {file}\")\n",
    "                    continue\n",
    "                \n",
    "                if part == 'Clustering':\n",
    "                    if value.is_integer():\n",
    "                        value = int(value)\n",
    "                    else:\n",
    "                        write_error(f'Clustering value at {i} is not an integer: {value} in {file}')\n",
    "                        continue\n",
    "                mi, ma = prediction_range[part]\n",
    "                if not (value >= mi and value <= ma):\n",
    "                    write_error(f'Value at {i} is not in the permitted range of ({mi},{ma}): {value} in {part} {file}')\n",
    "            if part == 'Classification':\n",
    "                if len(lines) != test_entries_class:\n",
    "                    write_error(f'Not correct number of predictions for classification. Got {len(lines)}, expected {test_entries_class}')\n",
    "            if part == 'Regression':\n",
    "                if len(lines) != test_entries_regre:\n",
    "                    write_error(f'Not correct number of predictions for regression. Got {len(lines)}, expected {test_entries_regre}')\n",
    "            if part == 'Clustering':\n",
    "                if len(lines) != test_entries_clust:\n",
    "                    write_error(f'Not correct number of predictions for clustering. Got {len(lines)}, expected {test_entries_clust}')\n",
    "                \n",
    "if errors == 0:\n",
    "    print ('Solutions parsed without error')\n",
    "else:\n",
    "    print (f'Solutions had {errors} errors')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check if all of the steps completed without error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parts of this submission had no errors\n"
     ]
    }
   ],
   "source": [
    "if all_errors == 0:\n",
    "    print ('All parts of this submission had no errors')\n",
    "else:\n",
    "    print (f'This submission had {all_errors} errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are done now! If you want some fireworks to celebrate. Run the cell below, but this is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"text-align: center;\">\n",
       "        <h1 style=\"color: green;\">🎉 All parts of this submission had no errors! 🎉</h1>\n",
       "        <img src=\"https://media.giphy.com/media/peAFQfg7Ol6IE/giphy.gif\" alt=\"Fireworks\" style=\"width: 50%; height: auto;\">\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "if all_errors == 0:\n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"text-align: center;\">\n",
    "        <h1 style=\"color: green;\">🎉 All parts of this submission had no errors! 🎉</h1>\n",
    "        <img src=\"https://media.giphy.com/media/peAFQfg7Ol6IE/giphy.gif\" alt=\"Fireworks\" style=\"width: 50%; height: auto;\">\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "else:\n",
    "    print(f'This submission had {all_errors} errors')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
