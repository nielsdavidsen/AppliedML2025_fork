{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter Optimization Example\n",
    "\n",
    "This Jupyter Notebook is made for illustrating - through a mixture of slides and code in an interactive fashion - the different methods for optimising Hyperparameters for Machine Learning models. First it shows the most naive, manual approach, then grid search, and finally bayesian optimization. \n",
    "\n",
    "\n",
    "### Authors and Date:\n",
    "- Christian Michelsen & Troels Petersen (Niels Bohr Institute)   \n",
    "- 2025-04-27 (latest update)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This notebook uses the __[HTRU2 Pulsar dataset](https://archive.ics.uci.edu/ml/datasets/HTRU2)__ dataset as example data for Hyperparameter Optimization (HPO).\n",
    "\n",
    "The focus on this small example is neither the actual code nor getting any specific results, but - hopefully - getting a better understanding of HPO. This is also why we don't describe the code in great detail - and simply load the dataset from a csv file directly - but the first part of the code should hopefully look familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Naive, manual approach\n",
    "2. Grid search\n",
    "3. Random search\n",
    "4. Bayesian optimization\n",
    "5. \"Full\" scan over parameter space\n",
    "6. New methods\n",
    "7. New software\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- __[HTRU2 Pulsar dataset](https://archive.ics.uci.edu/ml/datasets/HTRU2)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Focus on the understanding of HPO, not the actual code nor the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nomenclature (i.e. naming scheme)\n",
    "- Machine Learning Model: $\\mathcal{A}$\n",
    "- $N$ hyperparameters\n",
    "- Domain: $\\Lambda_n$\n",
    "- Hyperparameter configuration space: $\\mathbf{\\Lambda}=\\Lambda_1 \\times \\Lambda_2 \\times \\dots \\times \\Lambda_N $\n",
    "- Vector of hyperparameters: $\\mathbf{\\lambda} \\in \\mathbf{\\Lambda}$\n",
    "- Specific ML model: $\\mathcal{A}_\\mathbf{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Domain of hyperparameters:\n",
    "\n",
    "1. real\n",
    "2. integer\n",
    "3. binary\n",
    "4. categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goal:\n",
    "\n",
    "Given a dataset $\\mathcal{D}$, find the vector of HyperParameters $\\mathbf{\\lambda}^{*}$, which performes \"best\", i.e. minimises the expected loss function $\\mathcal{L}$ for the model $\\mathcal{A}_\\mathbf{\\lambda}$ on the test set of the data $D_\\mathrm{test}$:\n",
    "\n",
    "$$ \\mathbf{\\lambda}^{*} = \\mathop{\\mathrm{argmin}}_{\\mathbf{\\lambda} \\in \\mathbf{\\Lambda}} \\mathbb{E}_{D_\\mathrm{test} \\thicksim \\mathcal{D}} \\, \\left[ \\mathbf{V}\\left(\\mathcal{L}, \\mathcal{A}_\\mathbf{\\lambda}, D_\\mathrm{test}\\right) \\right]  $$\n",
    "\n",
    "In practice we have to approximate the expectation above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we import the modules we want to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "Make sure that you have some additional packages installed:\n",
    "\n",
    "pip install graphviz \n",
    "\n",
    "conda install -c conda-forge bayesian-optimization\n",
    "\n",
    "conda install -c conda-forge optuna\n",
    "\n",
    "pip install optuna-integration\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, poisson\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_SNR</th>\n",
       "      <th>STD_SNR</th>\n",
       "      <th>Kurtosis_SNR</th>\n",
       "      <th>Skewness_SNR</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.555184</td>\n",
       "      <td>61.719016</td>\n",
       "      <td>2.208808</td>\n",
       "      <td>3.662680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.358696</td>\n",
       "      <td>13.079034</td>\n",
       "      <td>13.312141</td>\n",
       "      <td>212.597029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.112876</td>\n",
       "      <td>62.070220</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>1.082920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146.568562</td>\n",
       "      <td>82.394624</td>\n",
       "      <td>-0.274902</td>\n",
       "      <td>-1.121848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.071070</td>\n",
       "      <td>29.760400</td>\n",
       "      <td>5.318767</td>\n",
       "      <td>28.698048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32.919732</td>\n",
       "      <td>65.094197</td>\n",
       "      <td>1.605538</td>\n",
       "      <td>0.871364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34.101171</td>\n",
       "      <td>62.577395</td>\n",
       "      <td>1.890020</td>\n",
       "      <td>2.572133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.107860</td>\n",
       "      <td>66.321825</td>\n",
       "      <td>1.456423</td>\n",
       "      <td>1.335182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>176.119565</td>\n",
       "      <td>59.737720</td>\n",
       "      <td>-1.785377</td>\n",
       "      <td>2.940913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>183.622910</td>\n",
       "      <td>79.932815</td>\n",
       "      <td>-1.326647</td>\n",
       "      <td>0.346712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean_SNR    STD_SNR  Kurtosis_SNR  Skewness_SNR  Class\n",
       "0   27.555184  61.719016      2.208808      3.662680      1\n",
       "1    1.358696  13.079034     13.312141    212.597029      1\n",
       "2   73.112876  62.070220      1.268206      1.082920      1\n",
       "3  146.568562  82.394624     -0.274902     -1.121848      1\n",
       "4    6.071070  29.760400      5.318767     28.698048      1\n",
       "5   32.919732  65.094197      1.605538      0.871364      1\n",
       "6   34.101171  62.577395      1.890020      2.572133      1\n",
       "7   50.107860  66.321825      1.456423      1.335182      1\n",
       "8  176.119565  59.737720     -1.785377      2.940913      1\n",
       "9  183.622910  79.932815     -1.326647      0.346712      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Pulsar_data.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We then divide the dataset in input features (X) and target (y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3278, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_SNR</th>\n",
       "      <th>STD_SNR</th>\n",
       "      <th>Kurtosis_SNR</th>\n",
       "      <th>Skewness_SNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>159.849498</td>\n",
       "      <td>76.740010</td>\n",
       "      <td>-0.575016</td>\n",
       "      <td>-0.941293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>4.243311</td>\n",
       "      <td>26.746490</td>\n",
       "      <td>7.110978</td>\n",
       "      <td>52.701218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>1.015050</td>\n",
       "      <td>10.449662</td>\n",
       "      <td>15.593479</td>\n",
       "      <td>316.011541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2.235786</td>\n",
       "      <td>19.071848</td>\n",
       "      <td>9.659137</td>\n",
       "      <td>99.294390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2.266722</td>\n",
       "      <td>15.512103</td>\n",
       "      <td>9.062942</td>\n",
       "      <td>99.652157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>121.404682</td>\n",
       "      <td>47.965569</td>\n",
       "      <td>0.663053</td>\n",
       "      <td>1.203139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>35.209866</td>\n",
       "      <td>60.573157</td>\n",
       "      <td>1.635995</td>\n",
       "      <td>1.609377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>199.577759</td>\n",
       "      <td>58.656643</td>\n",
       "      <td>-1.862320</td>\n",
       "      <td>2.391870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>0.663043</td>\n",
       "      <td>8.571517</td>\n",
       "      <td>23.415092</td>\n",
       "      <td>655.614875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>3.112876</td>\n",
       "      <td>16.855717</td>\n",
       "      <td>8.301954</td>\n",
       "      <td>90.378150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean_SNR    STD_SNR  Kurtosis_SNR  Skewness_SNR\n",
       "233   159.849498  76.740010     -0.575016     -0.941293\n",
       "831     4.243311  26.746490      7.110978     52.701218\n",
       "2658    1.015050  10.449662     15.593479    316.011541\n",
       "2495    2.235786  19.071848      9.659137     99.294390\n",
       "2603    2.266722  15.512103      9.062942     99.652157\n",
       "111   121.404682  47.965569      0.663053      1.203139\n",
       "1370   35.209866  60.573157      1.635995      1.609377\n",
       "1124  199.577759  58.656643     -1.862320      2.391870\n",
       "2170    0.663043   8.571517     23.415092    655.614875\n",
       "2177    3.112876  16.855717      8.301954     90.378150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='Class')\n",
    "y = df['Class']\n",
    "feature_names = df.columns.tolist()[:-1]\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=42)\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And check out the y values (which turns out to be balanced):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233     1\n",
       "831     1\n",
       "2658    0\n",
       "2495    0\n",
       "2603    0\n",
       "111     1\n",
       "1370    1\n",
       "1124    1\n",
       "2170    0\n",
       "2177    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    1319\n",
       "1    1303\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part A: Naïve Approach\n",
    "\n",
    "- Manual configuration\n",
    "- _\"[Babysitting is also known as Trial & Error or Grad Student Descent in the academic field](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3748021bc194ecbb8cab8a2861434bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='max_depth', max=10, min=1), IntSlider(value=1, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fit_and_grapth_estimator(estimator):\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = accuracy_score(y_train, estimator.predict(X_train))\n",
    "    print(f'Training Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    class_names = [str(i) for i in range(y_train.nunique())]\n",
    "    graph = Source(tree.export_graphviz(estimator, \n",
    "                                        out_file=None, \n",
    "                                        feature_names=feature_names, \n",
    "                                        class_names=class_names, \n",
    "                                        filled = True))\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "    return estimator\n",
    "\n",
    "\n",
    "def plot_tree(max_depth=1, min_samples_leaf=1):\n",
    "    \n",
    "    estimator = DecisionTreeClassifier(random_state=42, \n",
    "                                       max_depth=max_depth, \n",
    "                                       min_samples_leaf=min_samples_leaf)\n",
    "    \n",
    "    return fit_and_grapth_estimator(estimator)\n",
    "\n",
    "display(interactive(plot_tree, \n",
    "                    max_depth=(1, 10, 1), \n",
    "                    min_samples_leaf=(1, 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__(Test this interactively in notebook)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And test this configuration out on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual: 0.8201\n"
     ]
    }
   ],
   "source": [
    "clf_manual = DecisionTreeClassifier(random_state=42, \n",
    "                                    max_depth=10, \n",
    "                                    min_samples_leaf=5)\n",
    "\n",
    "clf_manual.fit(X_train, y_train)\n",
    "accuracy_manual = accuracy_score(y_test, clf_manual.predict(X_test))\n",
    "print(f'Accuracy Manual: {accuracy_manual:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part B: Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Grid Search: \n",
    "\n",
    "- _full factorial design_ \n",
    "- Cartesian product\n",
    "- Curse of dimensionality (grows exponentially)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![title](./images/GridSearch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__[Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    ")__ with Scikit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parameters_GridSearch = {'max_depth':[1, 10, 100], \n",
    "                         'min_samples_leaf':[1, 10, 100],\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf_DecisionTree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "GridSearch = GridSearchCV(clf_DecisionTree, \n",
    "                          parameters_GridSearch, \n",
    "                          cv=5, \n",
    "                          return_train_score=True, \n",
    "                          refit=True, \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "GridSearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "GridSearch_results = pd.DataFrame(GridSearch.cv_results_)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: \tBest parameters:  {'max_depth': 1, 'min_samples_leaf': 1} , Best scores: 0.8551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Grid Search: \\tBest parameters: \", GridSearch.best_params_, f\", Best scores: {GridSearch.best_score_:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 100}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.858779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841729</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>8</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.948021</td>\n",
       "      <td>0.954242</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.957102</td>\n",
       "      <td>0.955568</td>\n",
       "      <td>0.004633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.853053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846300</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>6</td>\n",
       "      <td>0.896042</td>\n",
       "      <td>0.898903</td>\n",
       "      <td>0.898475</td>\n",
       "      <td>0.893232</td>\n",
       "      <td>0.895615</td>\n",
       "      <td>0.896453</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 100}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 100, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.796190</td>\n",
       "      <td>0.841603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824190</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845154</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>7</td>\n",
       "      <td>0.896996</td>\n",
       "      <td>0.899857</td>\n",
       "      <td>0.898475</td>\n",
       "      <td>0.894185</td>\n",
       "      <td>0.896568</td>\n",
       "      <td>0.897216</td>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'min_samples_leaf': 100}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.003802      0.000573         0.001574        0.000114   \n",
       "1       0.003027      0.000130         0.001326        0.000050   \n",
       "2       0.002603      0.000052         0.001156        0.000008   \n",
       "3       0.008929      0.000200         0.001226        0.000154   \n",
       "4       0.007885      0.000104         0.001081        0.000012   \n",
       "5       0.005046      0.000192         0.001315        0.000407   \n",
       "6       0.009583      0.000145         0.001136        0.000060   \n",
       "7       0.008010      0.000121         0.001096        0.000001   \n",
       "8       0.005024      0.000115         0.001086        0.000003   \n",
       "\n",
       "  param_max_depth param_min_samples_leaf  \\\n",
       "0               1                      1   \n",
       "1               1                     10   \n",
       "2               1                    100   \n",
       "3              10                      1   \n",
       "4              10                     10   \n",
       "5              10                    100   \n",
       "6             100                      1   \n",
       "7             100                     10   \n",
       "8             100                    100   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0      {'max_depth': 1, 'min_samples_leaf': 1}           0.849524   \n",
       "1     {'max_depth': 1, 'min_samples_leaf': 10}           0.849524   \n",
       "2    {'max_depth': 1, 'min_samples_leaf': 100}           0.849524   \n",
       "3     {'max_depth': 10, 'min_samples_leaf': 1}           0.847619   \n",
       "4    {'max_depth': 10, 'min_samples_leaf': 10}           0.845714   \n",
       "5   {'max_depth': 10, 'min_samples_leaf': 100}           0.849524   \n",
       "6    {'max_depth': 100, 'min_samples_leaf': 1}           0.826667   \n",
       "7   {'max_depth': 100, 'min_samples_leaf': 10}           0.845714   \n",
       "8  {'max_depth': 100, 'min_samples_leaf': 100}           0.849524   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "1           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "2           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "3           0.822857           0.858779  ...         0.841729        0.011991   \n",
       "4           0.847619           0.853053  ...         0.846300        0.008757   \n",
       "5           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "6           0.796190           0.841603  ...         0.824190        0.015056   \n",
       "7           0.849524           0.854962  ...         0.845154        0.009863   \n",
       "8           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1            0.862184            0.858369   \n",
       "1                1            0.862184            0.858369   \n",
       "2                1            0.862184            0.858369   \n",
       "3                8            0.956128            0.948021   \n",
       "4                6            0.896042            0.898903   \n",
       "5                1            0.862184            0.858369   \n",
       "6                9            1.000000            1.000000   \n",
       "7                7            0.896996            0.899857   \n",
       "8                1            0.862184            0.858369   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.858913            0.859390            0.860343   \n",
       "1            0.858913            0.859390            0.860343   \n",
       "2            0.858913            0.859390            0.860343   \n",
       "3            0.954242            0.962345            0.957102   \n",
       "4            0.898475            0.893232            0.895615   \n",
       "5            0.858913            0.859390            0.860343   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "7            0.898475            0.894185            0.896568   \n",
       "8            0.858913            0.859390            0.860343   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.859840         0.001340  \n",
       "1          0.859840         0.001340  \n",
       "2          0.859840         0.001340  \n",
       "3          0.955568         0.004633  \n",
       "4          0.896453         0.002066  \n",
       "5          0.859840         0.001340  \n",
       "6          1.000000         0.000000  \n",
       "7          0.897216         0.001909  \n",
       "8          0.859840         0.001340  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clf_GridSearch = GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual:      0.8201\n",
      "Accuracy Grid Search: 0.8430\n"
     ]
    }
   ],
   "source": [
    "accuracy_GridSearch = accuracy_score(y_test, clf_GridSearch.predict(X_test))\n",
    "print(f'Accuracy Manual:      {accuracy_manual:.4f}')\n",
    "print(f'Accuracy Grid Search: {accuracy_GridSearch:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part C: Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $B$ function evaluations, $N$ hyperparameters, $y$ number of different values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{\\mathrm{Grid Search}} = B^{1/N}, \\quad y_{\\mathrm{Random Search}} = B  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/RandomSearch.png\" alt=\"Random Search\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- _\"This failure of grid search is the rule rather than the exception in high dimensional\n",
    "hyper-parameter optimization\"_ [Bergstra, 2012]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- useful baseline because (almost) no assumptions about the ML algorithm being optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__[Random Search](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)__ with __[Scikit Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)__ using __[Scipy Stats](https://docs.scipy.org/doc/scipy/reference/stats.html)__ as PDFs for the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "parameters_RandomSearch = {'max_depth': poisson(25), \n",
    "                           'min_samples_leaf': randint(1, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 9\n",
    "RandomSearch = RandomizedSearchCV(clf_DecisionTree, \n",
    "                                  param_distributions=parameters_RandomSearch, \n",
    "                                  n_iter=n_iter_search, \n",
    "                                  cv=5, \n",
    "                                  return_train_score=True,\n",
    "                                  random_state=42,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# fit the random search instance\n",
    "RandomSearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search: \tBest parameters:  {'max_depth': 26, 'min_samples_leaf': 83} , Best scores: 0.855\n"
     ]
    }
   ],
   "source": [
    "RandomSearch_results = pd.DataFrame(RandomSearch.cv_results_)                 \n",
    "print(\"Random Search: \\tBest parameters: \", RandomSearch.best_params_, f\", Best scores: {RandomSearch.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>{'max_depth': 23, 'min_samples_leaf': 72}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854308</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>7</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>26</td>\n",
       "      <td>83</td>\n",
       "      <td>{'max_depth': 26, 'min_samples_leaf': 83}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>{'max_depth': 17, 'min_samples_leaf': 24}</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.860952</td>\n",
       "      <td>0.868321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854310</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>6</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.879351</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>0.875596</td>\n",
       "      <td>0.881792</td>\n",
       "      <td>0.878146</td>\n",
       "      <td>0.002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>27</td>\n",
       "      <td>88</td>\n",
       "      <td>{'max_depth': 27, 'min_samples_leaf': 88}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_leaf': 64}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>27</td>\n",
       "      <td>89</td>\n",
       "      <td>{'max_depth': 27, 'min_samples_leaf': 89}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_depth': 22, 'min_samples_leaf': 42}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.856870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845540</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>9</td>\n",
       "      <td>0.866476</td>\n",
       "      <td>0.865999</td>\n",
       "      <td>0.862726</td>\n",
       "      <td>0.865110</td>\n",
       "      <td>0.864156</td>\n",
       "      <td>0.864893</td>\n",
       "      <td>0.001343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>21</td>\n",
       "      <td>62</td>\n",
       "      <td>{'max_depth': 21, 'min_samples_leaf': 62}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850500</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>8</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 64}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.008817      0.001745         0.002041        0.000655   \n",
       "1       0.005866      0.000255         0.001192        0.000045   \n",
       "2       0.007489      0.000121         0.001210        0.000047   \n",
       "3       0.005399      0.000091         0.001129        0.000010   \n",
       "4       0.005737      0.000056         0.001115        0.000027   \n",
       "5       0.005247      0.000063         0.001100        0.000031   \n",
       "6       0.006313      0.000096         0.001090        0.000002   \n",
       "7       0.005481      0.000097         0.001038        0.000002   \n",
       "8       0.005405      0.000077         0.001057        0.000026   \n",
       "\n",
       "  param_max_depth param_min_samples_leaf  \\\n",
       "0              23                     72   \n",
       "1              26                     83   \n",
       "2              17                     24   \n",
       "3              27                     88   \n",
       "4              31                     64   \n",
       "5              27                     89   \n",
       "6              22                     42   \n",
       "7              21                     62   \n",
       "8              20                     64   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0  {'max_depth': 23, 'min_samples_leaf': 72}           0.849524   \n",
       "1  {'max_depth': 26, 'min_samples_leaf': 83}           0.849524   \n",
       "2  {'max_depth': 17, 'min_samples_leaf': 24}           0.847619   \n",
       "3  {'max_depth': 27, 'min_samples_leaf': 88}           0.849524   \n",
       "4  {'max_depth': 31, 'min_samples_leaf': 64}           0.849524   \n",
       "5  {'max_depth': 27, 'min_samples_leaf': 89}           0.849524   \n",
       "6  {'max_depth': 22, 'min_samples_leaf': 42}           0.849524   \n",
       "7  {'max_depth': 21, 'min_samples_leaf': 62}           0.849524   \n",
       "8  {'max_depth': 20, 'min_samples_leaf': 64}           0.849524   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.862857           0.862595  ...         0.854308        0.010440   \n",
       "1           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "2           0.860952           0.868321  ...         0.854310        0.012162   \n",
       "3           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "4           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "5           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "6           0.836190           0.856870  ...         0.845540        0.015574   \n",
       "7           0.840000           0.862595  ...         0.850500        0.009778   \n",
       "8           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                7            0.862184            0.858369   \n",
       "1                1            0.862184            0.858369   \n",
       "2                6            0.875536            0.879351   \n",
       "3                1            0.862184            0.858369   \n",
       "4                1            0.862184            0.858369   \n",
       "5                1            0.862184            0.858369   \n",
       "6                9            0.866476            0.865999   \n",
       "7                8            0.862184            0.858369   \n",
       "8                1            0.862184            0.858369   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.858913            0.859390            0.860343   \n",
       "1            0.858913            0.859390            0.860343   \n",
       "2            0.878456            0.875596            0.881792   \n",
       "3            0.858913            0.859390            0.860343   \n",
       "4            0.858913            0.859390            0.861296   \n",
       "5            0.858913            0.859390            0.860343   \n",
       "6            0.862726            0.865110            0.864156   \n",
       "7            0.858913            0.859390            0.861296   \n",
       "8            0.858913            0.859390            0.861296   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.859840         0.001340  \n",
       "1          0.859840         0.001340  \n",
       "2          0.878146         0.002373  \n",
       "3          0.859840         0.001340  \n",
       "4          0.860031         0.001460  \n",
       "5          0.859840         0.001340  \n",
       "6          0.864893         0.001343  \n",
       "7          0.860031         0.001460  \n",
       "8          0.860031         0.001460  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomSearch_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual:        0.8201\n",
      "Accuracy Grid search:   0.8430\n",
      "Accuracy Random Search: 0.8430\n"
     ]
    }
   ],
   "source": [
    "clf_RandomSearch = RandomSearch.best_estimator_\n",
    "\n",
    "accuracy_RandomSearch = accuracy_score(y_test, clf_RandomSearch.predict(X_test))\n",
    "print(f'Accuracy Manual:        {accuracy_manual:.4f}')\n",
    "print(f'Accuracy Grid search:   {accuracy_GridSearch:.4f}')\n",
    "print(f'Accuracy Random Search: {accuracy_RandomSearch:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part D: Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Expensive black box functions $\\Rightarrow$ need of smart guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Probabilistic Surrogate Model (to be fitted)  \n",
    "   - Often Gaussian Processes \n",
    "2. Acquisition function  \n",
    "   - Exploitation / Exploration  \n",
    "   - Cheap to Computer\n",
    "  \n",
    "_[Brochu, Cora, de Freitas, 2010]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/BO1.png\" alt=\"Bayesian Optimization 1\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/BO2.png\" alt=\"Bayesian Optimization 2\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/comparison_rs_bo.png\" alt=\"BO vs. RS\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "__[Bayesian Optimization](https://arxiv.org/pdf/1012.2599v1.pdf)__ with the Python package __[BayesianOptimization](https://github.com/fmfn/BayesianOptimization)__:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def DecisionTree_CrossValidation(max_depth, min_samples_leaf, data, targets):\n",
    "    \"\"\"Decision Tree cross validation.\n",
    "       Fits a Decision Tree with the given paramaters to the target \n",
    "       given data, calculated a CV accuracy score and returns the mean.\n",
    "       The goal is to find combinations of max_depth, min_samples_leaf \n",
    "       that maximize the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    estimator = DecisionTreeClassifier(random_state=42, \n",
    "                                       max_depth=max_depth, \n",
    "                                       min_samples_leaf=min_samples_leaf)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets, scoring='accuracy', cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_DecisionTree(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to Decision Tree parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(max_depth, min_samples_leaf):\n",
    "        \"\"\"Wrapper of Decision Tree cross validation. \n",
    "           Notice how we ensure max_depth, min_samples_leaf \n",
    "           are casted to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return DecisionTree_CrossValidation(max_depth=int(max_depth), \n",
    "                                            min_samples_leaf=int(min_samples_leaf), \n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=2)\n",
    "    optimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8551   \u001b[0m | \u001b[0m38.08    \u001b[0m | \u001b[0m95.12    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.849    \u001b[0m | \u001b[0m73.47    \u001b[0m | \u001b[0m60.27    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8524   \u001b[0m | \u001b[0m16.45    \u001b[0m | \u001b[0m16.44    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8551   \u001b[0m | \u001b[0m6.75     \u001b[0m | \u001b[0m86.75    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8551   \u001b[0m | \u001b[0m22.46    \u001b[0m | \u001b[0m67.29    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8551   \u001b[0m | \u001b[0m21.86    \u001b[0m | \u001b[0m65.88    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8242   \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8551   \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m100.0    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8551   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m37.47    \u001b[0m |\n",
      "=================================================\n",
      "{'target': 0.8550716103235187, 'params': {'max_depth': 38.07947176588889, 'min_samples_leaf': 95.1207163345817}}\n"
     ]
    }
   ],
   "source": [
    "parameters_BayesianOptimization = {\"max_depth\": (1, 100), \n",
    "                                   \"min_samples_leaf\": (1, 100),\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_DecisionTree(X_train, \n",
    "                                             y_train, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "params = BayesianOptimization.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for key, val in params.items():\n",
    "    params[key] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf_BO = DecisionTreeClassifier(random_state=42, **params)\n",
    "clf_BO = clf_BO.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual:                0.8201\n",
      "Accuracy Grid Search:           0.8430\n",
      "Accuracy Random Search:         0.8430\n",
      "Accuracy Bayesian Optimization: 0.8430\n"
     ]
    }
   ],
   "source": [
    "accuracy_BayesianOptimization = accuracy_score(y_test, clf_BO.predict(X_test))\n",
    "print(f'Accuracy Manual:                {accuracy_manual:.4f}')\n",
    "print(f'Accuracy Grid Search:           {accuracy_GridSearch:.4f}')\n",
    "print(f'Accuracy Random Search:         {accuracy_RandomSearch:.4f}')\n",
    "print(f'Accuracy Bayesian Optimization: {accuracy_BayesianOptimization:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part D: Full Scan over Parameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Only possible in low-dimensional space, slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_depth_array = np.arange(1, 30)\n",
    "min_samples_leaf_array = np.arange(2, 31)\n",
    "Z = np.zeros((len(max_depth_array), len(min_samples_leaf_array)))\n",
    "\n",
    "for i, max_depth in enumerate(max_depth_array):\n",
    "    for j, min_samples_leaf in enumerate(min_samples_leaf_array):\n",
    "        \n",
    "        clf = DecisionTreeClassifier(random_state=42, \n",
    "                                     max_depth=max_depth, \n",
    "                                     min_samples_leaf=\n",
    "                                     min_samples_leaf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "        Z[i, j] = acc\n",
    "        \n",
    "# Notice: have to transpose Z to match up with imshow\n",
    "Z = Z.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# notice that we are setting the extent and origin keywords\n",
    "CS = ax.imshow(Z, extent=[1, 30, 2, 31], cmap='viridis', origin='lower')\n",
    "ax.set(xlabel='max_depth', ylabel='min_samples_leaf')\n",
    "\n",
    "fig.colorbar(CS);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sum up:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/Chart.png\" alt=\"Chart\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__[Guide To Hyperparameters Search For Deep Learning Models](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part E: New Methods\n",
    "\n",
    "Bayesian Optimization meets HyperBand (BOHB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "HyperBand:\n",
    "\n",
    "\n",
    "<img src=\"./images/sh.gif\" alt=\"BO vs. RS\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/comparison_rs_bo.png\" alt=\"BO vs. RS\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/comparison-1.png\" alt=\"BOHB\" width=\"600\"/>\n",
    "\n",
    "__[BOHB: Robust and Efficient Hyperparameter Optimization at Scale](https://www.automl.org/blog_bohb/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part F: New Software\n",
    "\n",
    "__[Optuna](https://optuna.org/)__ is a HyperParameter Optimisation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from optuna.pruners import MedianPruner\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_data_train = lgb.Dataset(X_train, label=y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    boosting_types = [\"gbdt\", \"rf\", \"dart\"]\n",
    "    boosting_type = trial.suggest_categorical(\"boosting_type\", boosting_types)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": 'auc',\n",
    "        \"boosting\": boosting_type,\n",
    "        \"max_depth\": 5,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 63),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-5, 10, log=True),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 10.0, 30.0),\n",
    "        \"bagging_freq\": 1, \"bagging_fraction\": 0.6,\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    N_iterations_max = 10_000\n",
    "    early_stopping_rounds = 10\n",
    "\n",
    "    if boosting_type == \"dart\":\n",
    "        N_iterations_max = 100\n",
    "        early_stopping_rounds = 0\n",
    "\n",
    "    cv_res = lgb.cv(\n",
    "        params,\n",
    "        lgb_data_train,\n",
    "        num_boost_round=N_iterations_max,\n",
    "        seed=42,\n",
    "        callbacks=[LightGBMPruningCallback(trial, \"auc\"),lgb.early_stopping(stopping_rounds=early_stopping_rounds),lgb.log_evaluation(period=0)],\n",
    "    )\n",
    "\n",
    "    num_boost_round = len(cv_res[\"valid auc-mean\"])\n",
    "    trial.set_user_attr(\"num_boost_round\", num_boost_round)\n",
    "\n",
    "    return cv_res[\"valid auc-mean\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:17,065] A new study created in memory with name: no-name-2876f96b-4690-4f8e-b83e-dbe8af7714a4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a857b792c8428db8b76a98881ea1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.923591 + 0.00625717\n",
      "[I 2025-04-28 10:24:17,217] Trial 0 finished with value: 0.923591091502377 and parameters: {'boosting_type': 'rf', 'max_depth': 39, 'min_child_weight': 8.632008168602535e-05, 'scale_pos_weight': 13.119890406724053}. Best is trial 0 with value: 0.923591091502377.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid's auc: 0.922688 + 0.00562831\n",
      "[I 2025-04-28 10:24:17,386] Trial 1 finished with value: 0.9226879026588939 and parameters: {'boosting_type': 'rf', 'max_depth': 45, 'min_child_weight': 1.3289448722869181e-05, 'scale_pos_weight': 29.398197043239886}. Best is trial 0 with value: 0.923591091502377.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid's auc: 0.931813 + 0.00638752\n",
      "[I 2025-04-28 10:24:17,604] Trial 2 finished with value: 0.9318133275583781 and parameters: {'boosting_type': 'gbdt', 'max_depth': 13, 'min_child_weight': 0.0006690421166498799, 'scale_pos_weight': 20.495128632644757}. Best is trial 2 with value: 0.9318133275583781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:17,990] Trial 3 finished with value: 0.9300085140349988 and parameters: {'boosting_type': 'dart', 'max_depth': 10, 'min_child_weight': 0.0005660670699258885, 'scale_pos_weight': 17.327236865873836}. Best is trial 2 with value: 0.9318133275583781.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid's auc: 0.925103 + 0.00664956\n",
      "[I 2025-04-28 10:24:18,071] Trial 4 finished with value: 0.925103266293118 and parameters: {'boosting_type': 'rf', 'max_depth': 33, 'min_child_weight': 0.035849855803404704, 'scale_pos_weight': 10.929008254399955}. Best is trial 2 with value: 0.9318133275583781.\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:18,211] Trial 5 pruned. Trial was pruned at iteration 50.\n",
      "[I 2025-04-28 10:24:18,366] Trial 6 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid's auc: 0.922706 + 0.00507721\n",
      "[I 2025-04-28 10:24:18,571] Trial 7 finished with value: 0.9227063697984439 and parameters: {'boosting_type': 'rf', 'max_depth': 43, 'min_child_weight': 0.0007417652034871827, 'scale_pos_weight': 20.401360423556216}. Best is trial 2 with value: 0.9318133275583781.\n",
      "[I 2025-04-28 10:24:18,716] Trial 8 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid's auc: 0.923603 + 0.00649557\n",
      "[I 2025-04-28 10:24:18,829] Trial 9 finished with value: 0.9236031526982261 and parameters: {'boosting_type': 'rf', 'max_depth': 14, 'min_child_weight': 1.867943489455631e-05, 'scale_pos_weight': 16.506606615265287}. Best is trial 2 with value: 0.9318133275583781.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:18,891] Trial 10 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid's auc: 0.932005 + 0.00572181\n",
      "[I 2025-04-28 10:24:19,226] Trial 11 finished with value: 0.9320045589835481 and parameters: {'boosting_type': 'gbdt', 'max_depth': 17, 'min_child_weight': 0.0014474404511749194, 'scale_pos_weight': 17.256467103396812}. Best is trial 11 with value: 0.9320045589835481.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:19,377] Trial 12 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid's auc: 0.932222 + 0.00647982\n",
      "[I 2025-04-28 10:24:19,640] Trial 13 finished with value: 0.9322223804893104 and parameters: {'boosting_type': 'gbdt', 'max_depth': 21, 'min_child_weight': 0.009013452524358742, 'scale_pos_weight': 16.365725002496163}. Best is trial 13 with value: 0.9322223804893104.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid's auc: 0.932962 + 0.00616164\n",
      "[I 2025-04-28 10:24:19,918] Trial 14 finished with value: 0.9329620531129151 and parameters: {'boosting_type': 'gbdt', 'max_depth': 24, 'min_child_weight': 0.5206341066619701, 'scale_pos_weight': 14.999056028284222}. Best is trial 14 with value: 0.9329620531129151.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's auc: 0.932264 + 0.00804279\n",
      "[I 2025-04-28 10:24:20,159] Trial 15 finished with value: 0.9322644588626462 and parameters: {'boosting_type': 'gbdt', 'max_depth': 27, 'min_child_weight': 0.4681880870979293, 'scale_pos_weight': 14.221884014764331}. Best is trial 14 with value: 0.9329620531129151.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:20,378] Trial 16 pruned. Trial was pruned at iteration 67.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:20,572] Trial 17 pruned. Trial was pruned at iteration 65.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:20,737] Trial 18 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:20,841] Trial 19 pruned. Trial was pruned at iteration 50.\n",
      "[I 2025-04-28 10:24:21,027] Trial 20 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:21,188] Trial 21 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:21,356] Trial 22 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:21,603] Trial 23 pruned. Trial was pruned at iteration 53.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:21,774] Trial 24 pruned. Trial was pruned at iteration 59.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:21,949] Trial 25 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:22,166] Trial 26 pruned. Trial was pruned at iteration 53.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:22,319] Trial 27 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:22,581] Trial 28 pruned. Trial was pruned at iteration 61.\n",
      "[I 2025-04-28 10:24:22,754] Trial 29 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.923732 + 0.00629018\n",
      "[I 2025-04-28 10:24:22,887] Trial 30 finished with value: 0.9237324157136173 and parameters: {'boosting_type': 'rf', 'max_depth': 31, 'min_child_weight': 0.01665309875195129, 'scale_pos_weight': 13.432990381665874}. Best is trial 14 with value: 0.9329620531129151.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:23,050] Trial 31 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:23,228] Trial 32 pruned. Trial was pruned at iteration 51.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:23,392] Trial 33 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:23,549] Trial 34 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:23,714] Trial 35 pruned. Trial was pruned at iteration 59.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid's auc: 0.923515 + 0.00569202\n",
      "[I 2025-04-28 10:24:23,855] Trial 36 finished with value: 0.9235154085925196 and parameters: {'boosting_type': 'rf', 'max_depth': 9, 'min_child_weight': 0.0004218437241982917, 'scale_pos_weight': 19.39629668550541}. Best is trial 14 with value: 0.9329620531129151.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:24,013] Trial 37 pruned. Trial was pruned at iteration 52.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:24,230] Trial 38 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:24,411] Trial 39 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid's auc: 0.922837 + 0.00554164\n",
      "[I 2025-04-28 10:24:24,576] Trial 40 finished with value: 0.922836814288155 and parameters: {'boosting_type': 'rf', 'max_depth': 16, 'min_child_weight': 0.0018621668902425658, 'scale_pos_weight': 24.793691766588957}. Best is trial 14 with value: 0.9329620531129151.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:24,729] Trial 41 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:24,930] Trial 42 pruned. Trial was pruned at iteration 52.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:25,087] Trial 43 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:25,248] Trial 44 pruned. Trial was pruned at iteration 50.\n",
      "[I 2025-04-28 10:24:25,420] Trial 45 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid's auc: 0.932303 + 0.00690571\n",
      "[I 2025-04-28 10:24:25,638] Trial 46 finished with value: 0.9323033503094471 and parameters: {'boosting_type': 'gbdt', 'max_depth': 23, 'min_child_weight': 0.000644240235865229, 'scale_pos_weight': 14.064321358945573}. Best is trial 14 with value: 0.9329620531129151.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:25,826] Trial 47 pruned. Trial was pruned at iteration 58.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid's auc: 0.923565 + 0.00628615\n",
      "[I 2025-04-28 10:24:25,970] Trial 48 finished with value: 0.9235653389617923 and parameters: {'boosting_type': 'rf', 'max_depth': 41, 'min_child_weight': 0.947321105347536, 'scale_pos_weight': 14.47732088897744}. Best is trial 14 with value: 0.9329620531129151.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid's auc: 0.933093 + 0.00551087\n",
      "[I 2025-04-28 10:24:26,315] Trial 49 finished with value: 0.933092803121566 and parameters: {'boosting_type': 'gbdt', 'max_depth': 22, 'min_child_weight': 0.2635136323609316, 'scale_pos_weight': 11.044943197048564}. Best is trial 49 with value: 0.933092803121566.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:26,493] Trial 50 pruned. Trial was pruned at iteration 61.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:26,700] Trial 51 pruned. Trial was pruned at iteration 60.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:26,926] Trial 52 pruned. Trial was pruned at iteration 61.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid's auc: 0.932337 + 0.00710258\n",
      "[I 2025-04-28 10:24:27,305] Trial 53 finished with value: 0.9323367384252235 and parameters: {'boosting_type': 'gbdt', 'max_depth': 30, 'min_child_weight': 0.06119043035142929, 'scale_pos_weight': 11.475363900116008}. Best is trial 49 with value: 0.933092803121566.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid's auc: 0.929566 + 0.00613555\n",
      "[I 2025-04-28 10:24:27,470] Trial 54 finished with value: 0.9295662941844272 and parameters: {'boosting_type': 'gbdt', 'max_depth': 30, 'min_child_weight': 0.08780958291799484, 'scale_pos_weight': 10.081216679848362}. Best is trial 49 with value: 0.933092803121566.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:27,654] Trial 55 pruned. Trial was pruned at iteration 58.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid's auc: 0.932481 + 0.00771392\n",
      "[I 2025-04-28 10:24:27,929] Trial 56 finished with value: 0.9324807206406296 and parameters: {'boosting_type': 'gbdt', 'max_depth': 35, 'min_child_weight': 0.21514933218601603, 'scale_pos_weight': 13.98202884389386}. Best is trial 49 with value: 0.933092803121566.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid's auc: 0.933327 + 0.00582276\n",
      "[I 2025-04-28 10:24:28,224] Trial 57 finished with value: 0.9333274990146139 and parameters: {'boosting_type': 'gbdt', 'max_depth': 47, 'min_child_weight': 0.17304919560013018, 'scale_pos_weight': 11.3763023335947}. Best is trial 57 with value: 0.9333274990146139.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:28,448] Trial 58 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:28,628] Trial 59 pruned. Trial was pruned at iteration 57.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:28,850] Trial 60 pruned. Trial was pruned at iteration 60.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:29,024] Trial 61 pruned. Trial was pruned at iteration 51.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:29,213] Trial 62 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:29,367] Trial 63 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's auc: 0.932908 + 0.00669412\n",
      "[I 2025-04-28 10:24:29,676] Trial 64 finished with value: 0.9329077283434337 and parameters: {'boosting_type': 'gbdt', 'max_depth': 43, 'min_child_weight': 0.1916075449595199, 'scale_pos_weight': 10.533498429785803}. Best is trial 57 with value: 0.9333274990146139.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid's auc: 0.933399 + 0.00639759\n",
      "[I 2025-04-28 10:24:29,958] Trial 65 finished with value: 0.9333988918824865 and parameters: {'boosting_type': 'gbdt', 'max_depth': 43, 'min_child_weight': 0.22241869921206867, 'scale_pos_weight': 10.662723742308922}. Best is trial 65 with value: 0.9333988918824865.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:30,133] Trial 66 pruned. Trial was pruned at iteration 61.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's auc: 0.933442 + 0.00652085\n",
      "[I 2025-04-28 10:24:30,403] Trial 67 finished with value: 0.9334422908744399 and parameters: {'boosting_type': 'gbdt', 'max_depth': 45, 'min_child_weight': 0.1271735448894815, 'scale_pos_weight': 10.096857292325948}. Best is trial 67 with value: 0.9334422908744399.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid's auc: 0.924293 + 0.00631914\n",
      "[I 2025-04-28 10:24:30,557] Trial 68 finished with value: 0.9242932575427331 and parameters: {'boosting_type': 'rf', 'max_depth': 46, 'min_child_weight': 0.83590765556976, 'scale_pos_weight': 10.194036629948728}. Best is trial 67 with value: 0.9334422908744399.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:30,712] Trial 69 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid's auc: 0.932717 + 0.00660894\n",
      "[I 2025-04-28 10:24:30,956] Trial 70 finished with value: 0.9327170621548326 and parameters: {'boosting_type': 'gbdt', 'max_depth': 41, 'min_child_weight': 2.551819679133171, 'scale_pos_weight': 10.597049011963843}. Best is trial 67 with value: 0.9334422908744399.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:31,100] Trial 71 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:31,273] Trial 72 pruned. Trial was pruned at iteration 52.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:31,420] Trial 73 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:31,593] Trial 74 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:31,738] Trial 75 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:31,913] Trial 76 pruned. Trial was pruned at iteration 50.\n",
      "[I 2025-04-28 10:24:32,083] Trial 77 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:32,256] Trial 78 pruned. Trial was pruned at iteration 52.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:32,420] Trial 79 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:32,655] Trial 80 pruned. Trial was pruned at iteration 52.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:32,959] Trial 81 pruned. Trial was pruned at iteration 61.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:33,120] Trial 82 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid's auc: 0.933736 + 0.00795931\n",
      "[I 2025-04-28 10:24:33,374] Trial 83 finished with value: 0.9337361149229348 and parameters: {'boosting_type': 'gbdt', 'max_depth': 33, 'min_child_weight': 0.2661001743254636, 'scale_pos_weight': 11.08984342655451}. Best is trial 83 with value: 0.9337361149229348.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:33,631] Trial 84 pruned. Trial was pruned at iteration 61.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:33,882] Trial 85 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid's auc: 0.923329 + 0.00655849\n",
      "[I 2025-04-28 10:24:34,012] Trial 86 finished with value: 0.9233292514559723 and parameters: {'boosting_type': 'rf', 'max_depth': 39, 'min_child_weight': 1.4368767427252667, 'scale_pos_weight': 13.049420206018091}. Best is trial 83 with value: 0.9337361149229348.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:34,184] Trial 87 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid's auc: 0.93248 + 0.00730065\n",
      "[I 2025-04-28 10:24:34,427] Trial 88 finished with value: 0.9324804038305414 and parameters: {'boosting_type': 'gbdt', 'max_depth': 45, 'min_child_weight': 0.023942537245259677, 'scale_pos_weight': 11.026741920172189}. Best is trial 83 with value: 0.9337361149229348.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:34,589] Trial 89 pruned. Trial was pruned at iteration 51.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/appml25/lib/python3.12/site-packages/lightgbm/callback.py:333: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 10:24:34,788] Trial 90 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:35,518] Trial 91 pruned. Trial was pruned at iteration 58.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:36,061] Trial 92 pruned. Trial was pruned at iteration 58.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:36,454] Trial 93 pruned. Trial was pruned at iteration 58.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:36,667] Trial 94 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:36,889] Trial 95 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid's auc: 0.93244 + 0.00561066\n",
      "[I 2025-04-28 10:24:37,204] Trial 96 finished with value: 0.9324403583944525 and parameters: {'boosting_type': 'gbdt', 'max_depth': 35, 'min_child_weight': 0.1251251915156914, 'scale_pos_weight': 12.40163008791551}. Best is trial 83 with value: 0.9337361149229348.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:37,361] Trial 97 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:37,526] Trial 98 pruned. Trial was pruned at iteration 50.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[I 2025-04-28 10:24:37,678] Trial 99 pruned. Trial was pruned at iteration 50.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=50),\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': CategoricalDistribution(choices=('gbdt', 'rf', 'dart')),\n",
       " 'max_depth': IntDistribution(high=63, log=False, low=2, step=1),\n",
       " 'min_child_weight': FloatDistribution(high=10.0, log=True, low=1e-05, step=None),\n",
       " 'scale_pos_weight': FloatDistribution(high=30.0, log=False, low=10.0, step=None)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see all info at the best trial use:\n",
    "study.best_trial\n",
    "\n",
    "# To print metric values for all trials:\n",
    "study.best_trial.intermediate_values\n",
    "\n",
    "# To see distributions from which optuna samples parameters:\n",
    "study.best_trial.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'max_depth': 33,\n",
       " 'min_child_weight': 0.2661001743254636,\n",
       " 'scale_pos_weight': 11.08984342655451}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To simply get the optimized parameters:\n",
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Happy HyperParameter Optimisation!\n",
    "\n",
    "...and remember, that this is useful but not essential in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook HyperparameterOptimization.ipynb to slides\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).\n",
      "[NbConvertApp] Writing 428641 bytes to HyperparameterOptimization.slides.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_scroll=True HyperparameterOptimization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
